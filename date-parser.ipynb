{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mWarning: Empirical distributions on disk may perform slow because GNU DBM is not available. Please install and configure gdbm library for Python for better speed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import pyprob\n",
    "from pyprob import Model\n",
    "import pyprob.distributions as dists\n",
    "\n",
    "import calendar\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHot2DCategorical(dists.Categorical):\n",
    "    def sample(self):\n",
    "        s = self._torch_dist.sample()\n",
    "        one_hot = self._probs * 0\n",
    "        for i, val in enumerate(s):\n",
    "            one_hot[i, int(val.item())] = 1\n",
    "        return one_hot\n",
    "    \n",
    "    def log_prob(self, x, *args, **kwargs):\n",
    "        # vector of one hot vectors\n",
    "        non_one_hot = torch.tensor([row.nonzero() for row in x])\n",
    "        return super().log_prob(non_one_hot, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateParser(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"Date with Unkown Format\")\n",
    "        self.possible_dividers = ['\\\\', '/', '-', ' ', '_', ':', '.']\n",
    "        self.longest_string = len('31 / September / 2000')\n",
    "        self.all_symbols = list(string.ascii_uppercase) + \\\n",
    "                           [str(d) for d in range(10)] + \\\n",
    "                           self.possible_dividers + \\\n",
    "                           [' ']\n",
    "    def get_index(self, letter):\n",
    "        return self.all_symbols.index(letter)\n",
    "    def pad(self, date_string):\n",
    "        return date_string + ' ' * (self.longest_string - len(date_string))\n",
    "    def forward(self):\n",
    "        # all dates are between 0 AD and 4000 AD\n",
    "        # sanple each digit such that the year is usually close to 2019\n",
    "        year_1 = int(pyprob.sample(dists.Categorical(torch.tensor(\n",
    "            [0.05, 0.4, 0.4, 0.03, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02]\n",
    "        ))).item())\n",
    "        year_2 = int(pyprob.sample(dists.Categorical(torch.tensor(\n",
    "            [0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.16, 0.7] if year_1 == 1 else\n",
    "            [0.7, 0.16, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02] if year_1 == 2 else\n",
    "            [0.1]*10\n",
    "        ))).item())\n",
    "        year_3 = int(pyprob.sample(dists.Categorical(torch.tensor([0.1]*10))).item())\n",
    "        year_4 = int(pyprob.sample(dists.Categorical(torch.tensor([0.1]*10))).item())\n",
    "        year = int(\"\".join(str(d) for d in [year_1, year_2, year_3, year_4]))\n",
    "        # sample month and day given the year\n",
    "        month = int(pyprob.sample(dists.Categorical(torch.tensor([1/12]*12))).item()) +1\n",
    "        if year == 0:\n",
    "            num_days = 31    # monthrange fails if year is 0\n",
    "        else:\n",
    "            num_days = calendar.monthrange(year, month)[1]             # number of days in this month\n",
    "        day_probs = [1/num_days]*num_days + [0.]*(31-num_days)     # probs of which day it is (in fixed length vector)\n",
    "        day = int(pyprob.sample(dists.Categorical(torch.tensor(day_probs))).item()) + 1\n",
    "        # sample format used to write day, month and year\n",
    "        yy = pyprob.sample(dists.Categorical(torch.tensor([0.5, 0.5]))).item()  # either yy or yyyy\n",
    "        m = pyprob.sample(dists.Categorical(torch.tensor([0.25]*4))).item()   # either m, mm or e.g. 'JAN'\n",
    "        d = pyprob.sample(dists.Categorical(torch.tensor([0.5, 0.5]))).item()   # either d or dd\n",
    "        real_date = {'day': day, 'month': month, 'year': year}\n",
    "        # put day, month and year in right format\n",
    "        if d:\n",
    "            day = str(day)\n",
    "        else:  # dd format\n",
    "            day = str(day).zfill(2)\n",
    "        # do month\n",
    "        if m == 0:\n",
    "            month = str(month)\n",
    "        elif m == 1:\n",
    "            month = str(month).zfill(2)\n",
    "        elif m == 2:\n",
    "            month = calendar.month_name[month]\n",
    "        else:\n",
    "            month = calendar.month_abbr[month]\n",
    "        # do year\n",
    "        if yy:\n",
    "            year = str(year).zfill(2)[-2:]\n",
    "        else:  # yyyy\n",
    "            year = str(year).zfill(4)\n",
    "        # sample order of day, month, year\n",
    "        # m/d/y or d/m/y or y/m/d (never y/d/m)\n",
    "        order = pyprob.sample(dists.Categorical(torch.tensor([1/3]*3))).item()\n",
    "        if order == 0:\n",
    "            date = [month, day, year]\n",
    "        elif order == 1:\n",
    "            date = [day, month, year]\n",
    "        else:\n",
    "            date = [year, month, day]\n",
    "        # select dividers\n",
    "        num_div = len(self.possible_dividers)\n",
    "        divider1 = int(pyprob.sample(dists.Categorical(torch.tensor([1/num_div]*num_div))).item())\n",
    "        divider2 = int(pyprob.sample(dists.Categorical(torch.tensor([1/num_div]*num_div))).item())\n",
    "        divider1 = self.possible_dividers[divider1]\n",
    "        divider2 = self.possible_dividers[divider2]\n",
    "        # sometimes put space before/after dividers\n",
    "        space1 = bool(pyprob.sample(dists.Categorical(torch.tensor([0.9, 0.1]))).item())\n",
    "        space2 = bool(pyprob.sample(dists.Categorical(torch.tensor([0.9, 0.1]))).item())\n",
    "        space3 = bool(pyprob.sample(dists.Categorical(torch.tensor([0.9, 0.1]))).item())\n",
    "        space4 = bool(pyprob.sample(dists.Categorical(torch.tensor([0.9, 0.1]))).item())\n",
    "        date =  \"\".join([date[0],\n",
    "                         ' ' if space1 else '',\n",
    "                         divider1,\n",
    "                         ' ' if space2 else '',\n",
    "                         date[1],\n",
    "                         ' ' if space3 else '',\n",
    "                         divider2,\n",
    "                         ' ' if space4 else '',\n",
    "                         date[2]]).upper()\n",
    "        # pad with spaces so tha number of observations is constant\n",
    "        padded_date = self.pad(date)\n",
    "        # make a categorical distribution that observes each letter independently (like 20 independent categoricals)\n",
    "        probs = torch.ones(self.longest_string, len(self.all_symbols))*0.001\n",
    "        for i, letter in enumerate(padded_date):\n",
    "            probs[i, self.get_index(letter)] = 1.\n",
    "        pyprob.observe(OneHot2DCategorical(probs),\n",
    "                       name=f\"date_string\")\n",
    "        \n",
    "        return real_date\n",
    "    def get_observes(self, date_string):\n",
    "        one_hot = torch.zeros(self.longest_string, len(self.all_symbols))\n",
    "        date_string = self.pad(date_string.upper())\n",
    "        for i, letter in enumerate(date_string):\n",
    "            one_hot[i, self.get_index(letter)] = 1.\n",
    "        return {'date_string': one_hot}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = DateParser()\n",
    "model.load_inference_network('artifacts/date-parser-5000000')\n",
    "# model.learn_inference_network(\n",
    "#     inference_network=pyprob.InferenceNetwork.LSTM,\n",
    "#     observe_embeddings={'date_string': {'dim' : 256}},\n",
    "#     num_traces=1000,\n",
    "#     batch_size=256,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent  | Time remain.| Progress             | Trace | Traces/sec\n",
      "0d:00:00:00 | 0d:00:00:00 | #################### | 10/10 | 34.23       \n",
      "{'day': 12, 'month': 9, 'year': 2009}\n",
      "{'day': 12, 'month': 9, 'year': 2009}\n",
      "{'day': 12, 'month': 9, 'year': 2009}\n"
     ]
    }
   ],
   "source": [
    "post = model.posterior_distribution(\n",
    "    observe=model.get_observes('12thSEPTEMBOR 2009'),\n",
    "    inference_engine=pyprob.InferenceEngine.IMPORTANCE_SAMPLING_WITH_INFERENCE_NETWORK,\n",
    "    num_traces=10\n",
    ")\n",
    "print(post.sample())\n",
    "print(post.sample())\n",
    "print(post.sample())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
