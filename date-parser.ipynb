{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mWarning: Empirical distributions on disk may perform slow because GNU DBM is not available. Please install and configure gdbm library for Python for better speed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import pyprob\n",
    "from pyprob import Model\n",
    "import pyprob.distributions as dists\n",
    "\n",
    "import calendar\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateParser(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"Date with Unkown Format\")\n",
    "        \n",
    "        self.possible_dividers = ['\\\\', '/', '-', ' ', '_', ':', '.']\n",
    "        \n",
    "        self.longest_string = len('31 / November / 2000')\n",
    "        self.all_symbols = list(string.ascii_uppercase) + \\\n",
    "                           [str(d) for d in range(10)] + \\\n",
    "                           self.possible_dividers + \\\n",
    "                           [' ']\n",
    "    \n",
    "    def get_index(self, letter):\n",
    "        return self.all_symbols.index(letter)\n",
    "    \n",
    "    def pad(self, date_string):\n",
    "        return date_string + ' ' * (self.longest_string - len(date_string))\n",
    "\n",
    "    def forward(self):\n",
    "\n",
    "        # all dates are between 0 AD and 4000 AD\n",
    "        # sanple each digit such that the year is usually close to 2019\n",
    "        year_1 = int(pyprob.sample(dists.Categorical(torch.tensor(\n",
    "            [0.05, 0.4, 0.4, 0.03, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02]\n",
    "        ))).item())\n",
    "        year_2 = int(pyprob.sample(dists.Categorical(torch.tensor(\n",
    "            [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.1, 0.5] if year_1 == 1 else\n",
    "            [0.5, 0.1, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05] if year_1 == 2 else\n",
    "            [0.1]*10\n",
    "        ))).item())\n",
    "        year_3 = int(pyprob.sample(dists.Categorical(torch.tensor([0.1]*10))).item())\n",
    "        year_4 = int(pyprob.sample(dists.Categorical(torch.tensor([0.1]*10))).item())\n",
    "        year = int(\"\".join(str(d) for d in [year_1, year_2, year_3, year_4]))\n",
    "\n",
    "        # sample month and day given the year\n",
    "        month = int(pyprob.sample(dists.Categorical(torch.tensor([1/12]*12))).item()) +1\n",
    "        num_days = calendar.monthrange(year, month)[1]             # number of days in this month\n",
    "        day_probs = [1/num_days]*num_days + [0.]*(31-num_days)     # probs of which day it is (in fixed length vector)\n",
    "        day = int(pyprob.sample(dists.Categorical(torch.tensor(day_probs))).item()) + 1\n",
    "\n",
    "        # sample format used to write day, month and year\n",
    "        yy = pyprob.sample(dists.Categorical(torch.tensor([0.5, 0.5]))).item()  # either yy or yyyy\n",
    "        m = pyprob.sample(dists.Categorical(torch.tensor([0.25]*4))).item()   # either m, mm or e.g. 'JAN'\n",
    "        d = pyprob.sample(dists.Categorical(torch.tensor([0.5, 0.5]))).item()   # either d or dd\n",
    "        \n",
    "        real_date = {'day': day, 'month': month, 'year': year}\n",
    "\n",
    "        # put day, month and year in right format\n",
    "        if d:\n",
    "            day = str(day)\n",
    "        else:  # dd format\n",
    "            day = str(day).zfill(2)\n",
    "        # do month\n",
    "        if m == 0:\n",
    "            month = str(month)\n",
    "        elif m == 1:\n",
    "            month = str(month).zfill(2)\n",
    "        elif m == 2:\n",
    "            month = calendar.month_name[month]\n",
    "        else:\n",
    "            month = calendar.month_abbr[month]\n",
    "        # do year\n",
    "        if yy:\n",
    "            year = str(year).zfill(2)[-2:]\n",
    "        else:  # yyyy\n",
    "            year = str(year).zfill(4)\n",
    "        \n",
    "        # sample order of day, month, year\n",
    "        # m/d/y or d/m/y or y/m/d (never y/d/m)\n",
    "        order = pyprob.sample(dists.Categorical(torch.tensor([1/3]*3))).item()\n",
    "        if order == 0:\n",
    "            date = [month, day, year]\n",
    "        elif order == 1:\n",
    "            date = [day, month, year]\n",
    "        else:\n",
    "            date = [year, month, day]\n",
    "            \n",
    "        # select dividers\n",
    "        num_div = len(self.possible_dividers)\n",
    "        divider1 = int(pyprob.sample(dists.Categorical(torch.tensor([1/num_div]*num_div))).item())\n",
    "        divider2 = int(pyprob.sample(dists.Categorical(torch.tensor([1/num_div]*num_div))).item())\n",
    "        divider1 = self.possible_dividers[divider1]\n",
    "        divider2 = self.possible_dividers[divider2]\n",
    "        \n",
    "        # sometimes put space before/after dividers\n",
    "        space1 = bool(pyprob.sample(dists.Categorical(torch.tensor([0.9, 0.1]))).item())\n",
    "        space2 = bool(pyprob.sample(dists.Categorical(torch.tensor([0.9, 0.1]))).item())\n",
    "        space3 = bool(pyprob.sample(dists.Categorical(torch.tensor([0.9, 0.1]))).item())\n",
    "        space4 = bool(pyprob.sample(dists.Categorical(torch.tensor([0.9, 0.1]))).item())\n",
    "\n",
    "        date =  \"\".join([date[0],\n",
    "                         ' ' if space1 else '',\n",
    "                         divider1,\n",
    "                         ' ' if space2 else '',\n",
    "                         date[1],\n",
    "                         ' ' if space3 else '',\n",
    "                         divider2,\n",
    "                         ' ' if space4 else '',\n",
    "                         date[2]]).upper()\n",
    "\n",
    "        # pad with spaces so tha number of observations is constant\n",
    "        padded_date = self.pad(date)\n",
    "        \n",
    "        # observe each letter from a categorical distribution\n",
    "        for i, letter in enumerate(padded_date):\n",
    "            probs = torch.ones(len(self.all_symbols))*0.001\n",
    "            probs[self.get_index(letter)] = 1.\n",
    "            pyprob.observe(dists.Categorical(probs),\n",
    "                           name=f\"letter_{i}\")\n",
    "        \n",
    "        return date, real_date\n",
    "    \n",
    "    def get_observes(self, date_string):\n",
    "        date_string = self.pad(date_string)\n",
    "        return {f\"letter{i}\": torch.tensor(self.get_index(letter))\n",
    "                for i, letter in enumerate(date_string)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DateParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent  | Time remain.| Progress             | Trace | Traces/sec\n",
      "0d:00:00:00 | 0d:00:00:00 | #################### | 20/20 | 111.14       \n",
      "JUNE:16\\50\n",
      "67 /NOVEMBER-24\n",
      "04-17  2103\n",
      "05 1\\ 75\n",
      "24 05\\34\n",
      "JUNE\\20.1742\n",
      "67  AUGUST  17\n",
      "SEPTEMBER:14 /14\n",
      "26: 1_05\n",
      "2064/JUN.14\n",
      "MAY\\04-1933\n",
      "51/JUN\\02\n",
      "3946-JUNE-21\n",
      "10 .6/03\n",
      "09.03_69\n",
      "JANUARY-24\\10\n",
      "1185:MAY.15\n",
      "25.JUN\\2087\n",
      "29\\01 2165\n",
      "16.DECEMBER 1944\n"
     ]
    }
   ],
   "source": [
    "for i in model.prior_distribution(20).values_numpy():\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'letter0': tensor(27),\n",
       " 'letter1': tensor(32),\n",
       " 'letter2': tensor(41),\n",
       " 'letter3': tensor(3),\n",
       " 'letter4': tensor(4),\n",
       " 'letter5': tensor(2),\n",
       " 'letter6': tensor(4),\n",
       " 'letter7': tensor(12),\n",
       " 'letter8': tensor(1),\n",
       " 'letter9': tensor(4),\n",
       " 'letter10': tensor(17),\n",
       " 'letter11': tensor(39),\n",
       " 'letter12': tensor(27),\n",
       " 'letter13': tensor(35),\n",
       " 'letter14': tensor(30),\n",
       " 'letter15': tensor(30),\n",
       " 'letter16': tensor(39),\n",
       " 'letter17': tensor(39),\n",
       " 'letter18': tensor(39),\n",
       " 'letter19': tensor(39)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_observes('16:DECEMBER 1944')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent  | Time remain.| Progress             | Trace       | Accepted|Smp reuse| Traces/sec\n",
      "0d:00:01:26 | 0d:00:00:00 | #################### | 10000/10000 |  42.64% |  93.75% | 115.36       \n"
     ]
    }
   ],
   "source": [
    "post = model.posterior_distribution(\n",
    "    observe=model.get_observes('16:DECEMBER 1944'),\n",
    "    inference_engine=pyprob.InferenceEngine.LIGHTWEIGHT_METROPOLIS_HASTINGS,\n",
    "    num_traces=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('02/2/1482', {'day': 2, 'month': 2, 'year': 1482})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
